{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "In this kernel, I show how I changed the backbone of the Faster-R-CNN model from ResNet50 to ResNet152. To achieve that, I used some of the source code of the torchvision and changed it manually."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "The following points are covered:\n",
    "* Create dataset\n",
    "* Create dataloader\n",
    "* Prepare the model\n",
    "* Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "from torchvision.models import (inception_v3,resnext50_32x4d,squeezenet1_0)\n",
    "\n",
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Prepare Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Device(Enum):\n",
    "    GPU = \"GPU\"\n",
    "    TPU = \"TPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_dir = Path(\"/kaggle/input/global-wheat-detection/\")\n",
    "test_train_ratio = 0.1\n",
    "batch_size=8\n",
    "seed = 0\n",
    "train_device = Device.GPU\n",
    "number_of_epochs = 40\n",
    "learning_rate = 0.0001\n",
    "#weight_decay = 0.01\n",
    "weight_decay = 1e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DatasetArguments:\n",
    "    data_dir: Path\n",
    "    images_lists_dict: dict\n",
    "    labels_csv_file_name: str\n",
    "\n",
    "@dataclass\n",
    "class DataLoaderArguments:\n",
    "    batch_size: int\n",
    "    num_workers: int\n",
    "    dataset_arguments: DatasetArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Split Data to train and val datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_images_file_names_from_csv(directory):\n",
    "    dataframe = pd.read_csv(os.path.join(directory, \"train.csv\"))\n",
    "    files = dataframe[\"image_id\"].unique().tolist()\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _choose_train_valid_file_names(file_names, valid_numbers, seed):\n",
    "    np.random.seed(seed)\n",
    "    valid_file_names = np.random.choice(file_names, valid_numbers, replace=False).tolist()\n",
    "    train_file_names = [file_name_i for file_name_i in file_names if file_name_i not in valid_file_names]\n",
    "    return train_file_names, valid_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "file_names = _get_images_file_names_from_csv(root_data_dir)\n",
    "valid_numbers = round(len(file_names) * test_train_ratio)\n",
    "train_file_names, valid_file_names = _choose_train_valid_file_names(file_names, valid_numbers, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_lists_dict = {\n",
    "    \"train\": train_file_names,\n",
    "    \"val\": valid_file_names,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_arguments = DatasetArguments(\n",
    "    data_dir=root_data_dir,\n",
    "    images_lists_dict=images_lists_dict,\n",
    "    labels_csv_file_name=\"train.csv\",\n",
    ")\n",
    "\n",
    "dataloaders_arguments = DataLoaderArguments(\n",
    "    batch_size=batch_size,\n",
    "    num_workers=1,\n",
    "    dataset_arguments=dataset_arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Prepare the transforms:\n",
    "I chose some of the transforms from this [notebook](https://www.kaggle.com/shonenkov/training-efficientdet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_set():\n",
    "    transforms_dict = {\n",
    "        'train': get_train_transforms(),\n",
    "        'val': get_valid_transforms()\n",
    "    }\n",
    "    return transforms_dict\n",
    "\n",
    "\n",
    "def get_train_transforms():\n",
    "    return Compose(\n",
    "        [OneOf([HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2,\n",
    "                                   val_shift_limit=0.2, p=0.9),\n",
    "                RandomBrightnessContrast(brightness_limit=0.2,\n",
    "                                         contrast_limit=0.2, p=0.9)],\n",
    "               p=0.9),\n",
    "            ToGray(p=0.01),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=0.5),\n",
    "            ToTensorV2(p=1.0)],\n",
    "        p=1.0,\n",
    "        bbox_params=BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0,\n",
    "            min_visibility=0,\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return Compose(\n",
    "        [\n",
    "            ToTensorV2(p=1.0),\n",
    "        ],\n",
    "        p=1.0,\n",
    "        bbox_params=BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0,\n",
    "            min_visibility=0,\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Create the pytorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _adjust_boxes_format(boxes):\n",
    "    # original format [xmin, ymin, width, height]\n",
    "    # new format [xmin, ymin, xmax, ymax]\n",
    "    adjusted_boxes = []\n",
    "    for box_i in boxes:\n",
    "        adjusted_box_i = [0, 0, 0, 0]\n",
    "        adjusted_box_i[0] = box_i[0]\n",
    "        adjusted_box_i[1] = box_i[1]\n",
    "        adjusted_box_i[2] = box_i[0] + box_i[2]\n",
    "        adjusted_box_i[3] = box_i[1] + box_i[3]\n",
    "        adjusted_boxes.append(adjusted_box_i)\n",
    "    return adjusted_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _areas(boxes):\n",
    "    # original format [xmin, ymin, width, height]\n",
    "    areas = []\n",
    "    for box_i in boxes:\n",
    "        areas.append(box_i[2] * box_i[3])\n",
    "    return areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Didn't understand\n",
    "\n",
    "\"\"\"\n",
    "# dataset\n",
    "class ObjectDetectionDataset(Dataset):\n",
    "    def __init__(self, images_root_directory,\n",
    "                 images_list,\n",
    "                 labels_csv_file_name,\n",
    "                 phase,\n",
    "                 transforms):\n",
    "        super(ObjectDetectionDataset).__init__()\n",
    "        self.images_root_directory = images_root_directory\n",
    "        self.phase = phase\n",
    "        self.transforms = transforms\n",
    "        self.images_list = images_list\n",
    "        if self.phase in [\"train\", \"val\"]:\n",
    "            self.labels_dataframe = pd.read_csv(os.path.join(images_root_directory, labels_csv_file_name))\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        sample = {\n",
    "            \"local_image_id\": None,\n",
    "            \"image_id\": None,\n",
    "            \"labels\": None,\n",
    "            \"boxes\": None,\n",
    "            \"area\": None,\n",
    "            \"iscrowd\": None\n",
    "        }\n",
    "\n",
    "        image_id = self.images_list[item]\n",
    "        image_path = os.path.join(self.images_root_directory,\n",
    "                                  \"train\" if self.phase in [\"train\", \"val\"] else \"test\",\n",
    "                                  image_id + \".jpg\")\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        sample[\"local_image_id\"] = image_id\n",
    "        sample[\"image_id\"] = torch.tensor([item])\n",
    "        if self.phase in [\"train\", \"val\"]:\n",
    "            boxes = self.labels_dataframe[self.labels_dataframe.image_id == image_id].bbox.values.tolist()\n",
    "            boxes = [eval(box_i) for box_i in boxes]\n",
    "            areas = _areas(boxes)\n",
    "            boxes = _adjust_boxes_format(boxes)\n",
    "\n",
    "            sample[\"labels\"] = torch.ones((len(boxes),), dtype=torch.int64)\n",
    "            sample[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            sample[\"area\"] = torch.as_tensor(areas, dtype=torch.float32)\n",
    "            sample[\"iscrowd\"] = torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "        if self.transforms is not None:\n",
    "            sample[\"image\"] = image\n",
    "            transformed_sample = self.transforms(image=sample[\"image\"],\n",
    "                                                 bboxes=sample[\"boxes\"],\n",
    "                                                 labels=sample[\"labels\"])\n",
    "            image = transformed_sample[\"image\"]\n",
    "            sample[\"boxes\"] = torch.as_tensor(transformed_sample[\"bboxes\"], dtype=torch.float32)\n",
    "            del sample[\"image\"]\n",
    "        return image, sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(arguments):\n",
    "    dataset = ObjectDetectionDataset(arguments.data_dir,\n",
    "                                     arguments.images_lists_dict[arguments.phase],\n",
    "                                     arguments.labels_csv_file_name,\n",
    "                                     arguments.phase,\n",
    "                                     arguments.transforms)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets_dictionary(arguments, input_size):\n",
    "    data_transforms = transform_set()\n",
    "    image_datasets = {\n",
    "        'train': None,\n",
    "        'val': None\n",
    "    }\n",
    "    for phase in ['train', 'val']:\n",
    "        arguments.phase = phase\n",
    "        arguments.transforms = data_transforms[phase]\n",
    "        image_datasets[phase] = create_dataset(arguments)\n",
    "    return image_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Create the pytorch dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders_dictionary(arguments, input_size):\n",
    "    batch_size = arguments.batch_size\n",
    "    num_workers = arguments.num_workers\n",
    "    image_datasets = create_datasets_dictionary(arguments.dataset_arguments, input_size)\n",
    "    dataloaders_dict = {x: DataLoader(image_datasets[x],\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      pin_memory=True,\n",
    "                                      num_workers=num_workers,\n",
    "                                      collate_fn=collate_fn) for x in ['train', 'val']}\n",
    "    return dataloaders_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Prepare the model\n",
    "I used the code here:\n",
    "[torchvision source code](https://github.com/pytorch/vision/blob/3d65fc6723f1e0709916f24d819d6e17a925b394/torchvision/models/detection/backbone_utils.py#L44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/squeezenet1_0-a815701f.pth\" to /root/.cache/torch/checkpoints/squeezenet1_0-a815701f.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756f43d097a84a25807c396180f09157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5017600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class SqueezeFeatures(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SqueezeFeatures, self).__init__()\n",
    "        base_model =  squeezenet1_0(pretrained=True)\n",
    "\n",
    "        self.seq1 = nn.Sequential(base_model.features \n",
    "                                  )\n",
    "        self.out_channels = 512\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq1(x)\n",
    "\n",
    "        return x\n",
    "backbone = SqueezeFeatures()\n",
    "backbone.out_channels = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasterrcnn_squeeze(pretrained=False, progress=True,\n",
    "                            num_classes=2, pretrained_backbone=True,\n",
    "                             trainable_backbone_layers=3, **kwargs):\n",
    "    assert trainable_backbone_layers <= 5 and trainable_backbone_layers >= 0\n",
    "    # dont freeze any layers if pretrained model or backbone is not used\n",
    "    if not (pretrained or pretrained_backbone):\n",
    "        trainable_backbone_layers = 5\n",
    "    if pretrained:\n",
    "        # no need to download the backbone if pretrained is set\n",
    "        pretrained_backbone = False\n",
    "    model = FasterRCNN(backbone, num_classes, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    model = fasterrcnn_squeeze(pretrained=False)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_device(train_device):\n",
    "    if train_device == Device.GPU:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda:0\")\n",
    "        else:\n",
    "            raise ValueError(\"No GPU was found\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_training_device(train_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = create_dataloaders_dictionary(dataloaders_arguments,input_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Some basic calculations that could be useful later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_size = len(dataloaders[\"train\"].dataset)\n",
    "number_of_iteration_per_epoch = int(train_dataset_size / dataloaders_arguments.batch_size)\n",
    "total_number_of_iteration = number_of_epochs * number_of_iteration_per_epoch\n",
    "learning_rate_step_size = 2 * number_of_iteration_per_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learnable_parameters(model, feature_extract):\n",
    "    params_to_update = model.parameters()\n",
    "\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\", name)\n",
    "    return params_to_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = get_learnable_parameters(model, feature_extract=False)\n",
    "optimizer = optim.Adam(params_to_update, lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer,\n",
    "                                                              T_0=learning_rate_step_size,\n",
    "                                                              T_mult=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_model(model, model_path):\n",
    "    torch.save(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the checkpoint helps to starting training from a certain point.\n",
    "def _save_checkpoint(epoch, model, optimizer, checkpoint_path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(epoch,model, optimizer):\n",
    "    model_path = \"/kaggle/working/best_model_epoch_{epoch}.pth\"\n",
    "    _save_model(model.state_dict(), model_path)\n",
    "    checkpoint_path = \"/kaggle/working/checkpoint_{epoch}.pth\"\n",
    "    _save_checkpoint(epoch, model, optimizer, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector:\n",
    "    def fit_model(self):\n",
    "        start_epoch = 0\n",
    "        iteration_i = 0\n",
    "        for current_epoch in range(start_epoch, number_of_epochs):\n",
    "            running_loss = 0\n",
    "            print(f\"Starting Epoch: {current_epoch}\")\n",
    "            progress_bar = tqdm(dataloaders[\"train\"])\n",
    "            for inputs, labels in  progress_bar:\n",
    "                running_loss_i = self.training_round(inputs, labels)\n",
    "                running_loss += running_loss_i\n",
    "                current_running_error = running_loss/((iteration_i - \n",
    "                                                      current_epoch * \n",
    "                                                      number_of_iteration_per_epoch + 1)*batch_size)\n",
    "                progress_bar.set_description(f\"Running train loss: {current_running_error}\")\n",
    "                iteration_i += 1\n",
    "            epoch_loss = running_loss / len(dataloaders[\"train\"].dataset)\n",
    "            print(f\"Finishing Current epoch: {current_epoch} ... training loss: {epoch_loss}\")\n",
    "            print(\"saving the model and checkpoint: \")\n",
    "            save_model(current_epoch, model, optimizer)\n",
    "            for inputs, labels in tqdm(dataloaders[\"val\"]):\n",
    "                self.validation_round(inputs, labels)\n",
    "\n",
    "    def training_round(self, inputs, labels):\n",
    "        inputs = list(image.to(device) for image in inputs)\n",
    "        inputs = torch.stack(inputs)\n",
    "        labels = [{k: v.to(device) for k, v in t.items() if not isinstance(v, str)} for t in labels]\n",
    "        model.train()\n",
    "        loss_dict = model(inputs, labels)\n",
    "        loss = sum(loss for loss in loss_dict.values())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        lr_scheduler.step()\n",
    "        running_loss_i = loss.item() * inputs.size(0) \n",
    "        return running_loss_i\n",
    "\n",
    "    def validation_round(self, inputs, labels):\n",
    "        model.eval()\n",
    "        inputs = list(image.to(device) for image in inputs)\n",
    "        inputs = torch.stack(inputs)\n",
    "        labels = [{k: v.to(device) for k, v in t.items() if not isinstance(v, str)} for t in labels]\n",
    "        outputs = model(inputs)\n",
    "        outputs = [{k: v.to(\"cpu\") for k, v in t.items()} for t in outputs]\n",
    "        # Note: I used here MSCOCO evaluation metric locally. Unfortunately, I could not run in this kernel.\n",
    "        # I appreciate it if you can help here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector  =  Detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/conda-bld/pytorch_1587428398394/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "Running train loss: 1.6915589272975922: 100%|██████████| 380/380 [06:20<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 0 ... training loss: 1.6937875951859949\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  1.97it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.424961409387313: 100%|██████████| 380/380 [06:11<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 1 ... training loss: 1.430593667922441\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:22<00:00,  1.93it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.3748599844765288: 100%|██████████| 380/380 [06:30<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 2 ... training loss: 1.3839170331226194\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:22<00:00,  1.92it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.3199686541881013: 100%|██████████| 380/380 [06:10<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 3 ... training loss: 1.3321422781397703\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  2.04it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.305864677298814: 100%|██████████| 380/380 [06:09<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 4 ... training loss: 1.321349238689709\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:22<00:00,  1.93it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.2219738947880732: 100%|██████████| 380/380 [06:04<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 5 ... training loss: 1.2396836613792048\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  2.03it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.2542582509431197: 100%|██████████| 380/380 [06:08<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 6 ... training loss: 1.2757409350831204\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  1.97it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.1864389202699488: 100%|██████████| 380/380 [06:05<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 7 ... training loss: 1.20988632976145\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  2.05it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.2013408553969: 100%|██████████| 380/380 [06:08<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 8 ... training loss: 1.2282483580869492\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  1.96it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.1590448380435954: 100%|██████████| 380/380 [06:05<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 9 ... training loss: 1.1880591357021306\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:20<00:00,  2.06it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.1490648352182828: 100%|██████████| 380/380 [06:09<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 10 ... training loss: 1.1808571429120693\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:22<00:00,  1.95it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.1357131319887497: 100%|██████████| 380/380 [06:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 11 ... training loss: 1.1701286814429543\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  1.98it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.1492147875987753: 100%|██████████| 380/380 [06:19<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 12 ... training loss: 1.1870677120914885\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  1.96it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.1282354218662543: 100%|██████████| 380/380 [06:14<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 13 ... training loss: 1.1683702787705874\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:22<00:00,  1.92it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.1381327804877672: 100%|██████████| 380/380 [06:20<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 14 ... training loss: 1.1816187497027149\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  1.97it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.072003055222427: 100%|██████████| 380/380 [06:25<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 15 ... training loss: 1.1157871062262412\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:22<00:00,  1.91it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.0782763508684707: 100%|██████████| 380/380 [06:25<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 16 ... training loss: 1.125157931341013\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  1.96it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.0684210222674257: 100%|██████████| 380/380 [06:13<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 17 ... training loss: 1.1176894488541975\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  1.99it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.1047083263720698: 100%|██████████| 380/380 [06:21<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 18 ... training loss: 1.1585610379343447\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  2.02it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.0874381094498742: 100%|██████████| 380/380 [06:10<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 19 ... training loss: 1.143314375943346\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:22<00:00,  1.95it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.0741930129379034: 100%|██████████| 380/380 [06:12<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 20 ... training loss: 1.132219249473416\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  1.99it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.0390877670183443: 100%|██████████| 380/380 [06:20<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 21 ... training loss: 1.0979557169284746\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  2.01it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.089596115386308: 100%|██████████| 380/380 [06:14<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 22 ... training loss: 1.1541966755870774\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:42<00:00,  1.01it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.0090801162696061: 100%|██████████| 380/380 [06:16<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 23 ... training loss: 1.0715659732718084\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:22<00:00,  1.87it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.070985359425592: 100%|██████████| 380/380 [06:19<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 24 ... training loss: 1.1401267067402876\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:22<00:00,  1.93it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.032435616298958: 100%|██████████| 380/380 [06:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 25 ... training loss: 1.101808760477149\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  2.00it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.043551614278643: 100%|██████████| 380/380 [06:01<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 26 ... training loss: 1.1164214898475073\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  2.03it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.0080247927063513: 100%|██████████| 380/380 [06:09<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 27 ... training loss: 1.0810700675401448\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  2.01it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.0226576300520522: 100%|██████████| 380/380 [06:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 28 ... training loss: 1.0994580054314553\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:20<00:00,  2.06it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.0151463978739415: 100%|██████████| 380/380 [06:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 29 ... training loss: 1.0940576461935232\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  2.00it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.028768283928313: 100%|██████████| 380/380 [06:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 30 ... training loss: 1.1114492659041062\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:20<00:00,  2.05it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 0.9692157625136875: 100%|██████████| 380/380 [06:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 31 ... training loss: 1.0496645016946655\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  2.01it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 1.0055258584398667: 100%|██████████| 380/380 [06:08<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 32 ... training loss: 1.091638086105995\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:20<00:00,  2.05it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 0.9740908777771088: 100%|██████████| 380/380 [06:08<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 36 ... training loss: 1.0677781427016528\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:20<00:00,  2.07it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 0.9563007584864573: 100%|██████████| 380/380 [06:10<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 37 ... training loss: 1.050796880866542\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  2.02it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 0.9671459932361494: 100%|██████████| 380/380 [06:10<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 38 ... training loss: 1.0652622534195268\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  1.96it/s]\n",
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train loss: 0.9610064952925452: 100%|██████████| 380/380 [06:10<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Current epoch: 39 ... training loss: 1.061032204288739\n",
      "saving the model and checkpoint: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:21<00:00,  2.02it/s]\n"
     ]
    }
   ],
   "source": [
    "## The model will be saved for each epoch\n",
    "detector.fit_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "**I appreciate your feedback and upvote if you think it was useful**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1614bb80f22e428b9258d4a91ba80f5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "4b27a31f80314d1791f1d04464126b6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5a35fee4dff240078eb372c786df148c",
       "max": 5017600.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1614bb80f22e428b9258d4a91ba80f5c",
       "value": 5017600.0
      }
     },
     "56d5db263bae46119d98de67ad66ea39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5a35fee4dff240078eb372c786df148c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "756f43d097a84a25807c396180f09157": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4b27a31f80314d1791f1d04464126b6f",
        "IPY_MODEL_bb3cfcad2c1541859358738da9729fe0"
       ],
       "layout": "IPY_MODEL_d10b69739604448eb6e16d4d4fa9d289"
      }
     },
     "bb3cfcad2c1541859358738da9729fe0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_eaf017b39a14423787d89972b462078e",
       "placeholder": "​",
       "style": "IPY_MODEL_56d5db263bae46119d98de67ad66ea39",
       "value": " 4.79M/4.79M [00:35&lt;00:00, 143kB/s]"
      }
     },
     "d10b69739604448eb6e16d4d4fa9d289": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eaf017b39a14423787d89972b462078e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
